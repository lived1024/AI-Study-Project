# 언어 모델의 특성 : DB가 아님!!!!
- RAG를 사용한다는 것은 오픈 북 시험과 같다고 보면 된다.

## Grounding
사실에 기반한 답변

### Grounding 주요방식 - RAG
- RAG(Retrieval Augmented Generation)
  - Retrieval   : 쪽지를 만들어서
  - Augmented   : (생성하기 전에 LLM에게 패스하여) 더 나아진
  - Generation  : 생성

### RAG 방법
- RAG 버전 1
  - 프롬프트에 데이터 포함
  - API call로 데이터 가져오기
- RAG 버전 2
  - 미리 저장되어 있는 데이터를 가져와서 프롬프트를 만듬 - embedding
  - LLM 모델을 몇 번 쓸 수도 있음
- RAG 버전 3
  - Vector DB를 만들고 데이터를 저장
  - Embedding으로 데이터를 저장하고 찾을 때도 씀
- RAG 버전 4
  - Fine Tuning을 통한 LLM 서비스 자체를 업그레이드

### Embedding
#### Embed
- 일반적 의미 : 어떤 것을 다른 것에 삽입하거나 통합하는 행위(웹 페이지에 비디오나 지도 등의 외부 컨텐츠를 '임베드'하는 것)
- 기술적 의미 : 특정 데이터나 기능을 한 시스템 또는 장치 안에 내장시키는 것을 의미
#### AI에서 Embedding이란?
데이터를 벡터의 형태로 표현하는 과정을 의미한다.   
이 벡터는 원래의 텍스트 데이터보다 낮은 차원을 가지며, 기계학습모델이 이해할 수 있는 형태로 변환된다.   
이런 벡터를 '임베딩 벡터'라고 하며, 이는 데이터의 의미적, 문맥적 특성을 수치화 한 것이다.   
- 예시
  - 경도/위도와 같은 위치정보
    - [37.5519, 126.9918] : 서울(부산과 비교적 가까운 숫자)
    - [35.2100, 129.0689] : 부산(서울과 비교적 가까운 숫자)
    - [47.6061, 122.3328] : 시애틀(부산, 서울과는 비교적 먼 숫자)
  - 마트 내에서 상품이 진열된 위치(3번 선반, 2층)
  - 언어모델 내
    - 애들 - [3,6,23,64,2364...] : 학생들과 비교적 가까운 숫자
    - 학생들 - [4,7,12,51,2325...] : 애들과 비교적 가까운 숫자
    - 만두 - [2356,2346,1274,7324...] : 학생들, 애들과 먼 숫자
  - 벡터 - [1,2,3,4,5...] : 숫자리스트

#### Semantic search
- <b><u>정확한 문자열이 아닌 "의미"로 찾기</u></b>
- RAG를 위한 주요 기술(유일 X)
- 검색 시, 쿼리의 의미적 표현에서 가장 관련성 높은 문서를 찾기 위해 <u>유사성 검색</u>이 수행